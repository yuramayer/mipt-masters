
# Отчёт по анализу отзывов

## 1. Данные
У нас были тексты отзывов (негатив/позитив). Всего +- 92878 штук.  
Первым делом разбил на train/val/test, чтоб всё честно проверить.
Баланс по классам получился искусственный, но для нашей задачи более-менее норм.

## 2. Предобработка
Тексты почистил: убрал html, ссылки, лишние знаки. Привёл к нижнему регистру + лемматизацию
Сделал токенизацию. Для эмбеддингов (w2v/ft) - сплит по словам
С nltk были проблемы при токенизации, пришлось костылить - см. решение в Параграфе 2

## 3. Модели и результаты
**TF-IDF + логрег**  
- лучшие параметры: {'vector_size': 300, 'window': 10, 'sg': 1}  
- F1 на тесте: 0.95, ROC AUC: 0.98

**Word2Vec + логрег**  
- параметры: {'vector_size': 300, 'window': 10, 'sg': 1}  
- F1 на тесте: 0.94, ROC AUC: 0.98

**FastText + логрег**  
- vector_size=100, window=5, sg=1  
- F1 на тесте: 0.94, ROC AUC: 0.98

(таблица и графики см. юпитер ноутбук)

## 4. Ошибки
Все модели валились на:
- коротких/мутных отзывах, 
- эмоционально комплексных отзывах, когда люди писали и плюсы, и минусы
- на ошибочных отзывах (тут неудивительно)  
- по словам одногруппников - на редких словах и сарказме
Интересно было бы проверить на последнем фаст-текст. Но у меня были семплы без редких слов

Примеры общих ошибок есть в ноуте - видно, что смысл неочевидный

## 5. Выводы
1. TF-IDF дал нормальный базовый результат, но семантики не видит.  
2. Word2Vec чуть лучше вытянул F1, ловит смысл слов  
3. FastText классно работает с редкими словами, но общий скор оказался хуже чем у w2v. 
4. Данные тоже не идеальные, см. те же ошибочные разметки, так что хороший шаг - собрать/почистить побольше отзывов
