{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HW1_Сравнительный анализ моделей классификации отзывов\n",
        "\n",
        "**ФИО Студента:**\n",
        "\n",
        "**Дата Выполнения:**\n",
        "\n",
        "-----\n",
        "\n",
        "## **1. Подготовка данных и EDA**\n",
        "\n",
        "### **1.1. Загрузка и подготовка библиотек**\n",
        "\n",
        "Начнем с установки и импорта необходимых библиотек для нашего проекта."
      ],
      "metadata": {
        "id": "v55Iq6rvqx4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка библиотек\n",
        "!pip install pymorphy3\n",
        "!pip install gensim\n",
        "!pip install lime"
      ],
      "metadata": {
        "id": "DdwsUjJurK8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Основные библиотеки\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import Counter\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "# NLP библиотеки\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import pymorphy3\n",
        "\n",
        "# Embeddings\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "\n",
        "# ML\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                           f1_score, confusion_matrix, classification_report,\n",
        "                           roc_auc_score, roc_curve)\n",
        "\n",
        "# Визуализация\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Интерпретируемость\n",
        "import shap\n",
        "import lime\n",
        "\n",
        "# Настройки\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "np.random.seed(42)\n",
        "\n",
        "# Создание структуры папок\n",
        "folders = ['data', 'models', 'results', 'visualizations', 'reports']\n",
        "for folder in folders:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "# Загрузка ресурсов NLTK\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "print(\"NLTK ресурсы загружены\")\n",
        "\n",
        "# Инициализация морфологического анализатора и стоп-слов\n",
        "morph = pymorphy3.MorphAnalyzer()\n",
        "stop_words_ru = set(stopwords.words('russian'))\n",
        "stop_words_en = set(stopwords.words('english'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "VB8yOAWQqx4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2. Загрузка и первичный анализ данных**\n",
        "\n",
        "Загрузим датасет и проведем базовый анализ, чтобы понять его структуру."
      ],
      "metadata": {
        "id": "PNAdNVD6qx4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка датасета\n",
        "from datasets import load_dataset\n",
        "df = load_dataset(\"d0rj/geo-reviews-dataset-2023\")\n",
        "df = pd.DataFrame(df['train'])\n",
        "\n",
        "# ЗАДАНИЕ: Удалите нейтральные отзывы (рейтинг 3) и создайте бинарную целевую переменную 'sentiment'.\n",
        "# 1 - позитивный отзыв (рейтинг 4, 5)\n",
        "# 0 - негативный отзыв (рейтинг 1, 2)\n",
        "# Удалите строки с отсутствующими значениями в 'sentiment'.\n",
        "\n",
        "\n",
        "\n",
        "# ЗАДАНИЕ: Сбалансируйте классы, чтобы количество позитивных и негативных отзывов было одинаковым.\n",
        "\n",
        "\n",
        "\n",
        "# Вывод базовой информации о датасете\n",
        "print(\"Исследовательский анализ данных:\")\n",
        "print(f\"\\nРазмер датасета: {df.shape}\")\n",
        "print(f\"\\nТипы данных:\\n{df.dtypes}\")\n",
        "print(f\"\\nПропущенные значения:\\n{df.isnull().sum()}\")\n",
        "\n",
        "# Распределение классов\n",
        "class_distribution = df['sentiment'].value_counts()\n",
        "print(\"\\nРаспределение классов:\")\n",
        "print(f\"Позитивные (1): {class_distribution.get(1, 0)} ({class_distribution.get(1, 0)/len(df)*100:.1f}%)\")\n",
        "print(f\"Негативные (0): {class_distribution.get(0, 0)} ({class_distribution.get(0, 0)/len(df)*100:.1f}%)\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "YhmPQkGiqx4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3. Исследовательский анализ данных (EDA)**\n",
        "\n",
        "Проведем более глубокий анализ текстовых данных и визуализируем результаты."
      ],
      "metadata": {
        "id": "bIWHpkC4qx4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ЗАДАНИЕ: Добавьте в датафрейм столбцы с длиной текста, количеством слов и предложений.\n",
        "# df['text_length'] = ...\n",
        "# df['word_count'] = ...\n",
        "# df['sentence_count'] = ...\n",
        "\n",
        "# Вывод статистик по текстам\n",
        "print(\"\\nСтатистика текстов:\")\n",
        "print(df[['text_length', 'word_count', 'sentence_count']].describe())\n",
        "\n",
        "# ЗАДАНИЕ: Создайте 6 графиков для визуализации EDA, например такие:\n",
        "# 1. Распределение классов\n",
        "# 2. Распределение количества слов\n",
        "# 3. Boxplot количества слов по классам\n",
        "# 4. Распределение количества предложений\n",
        "# 5. Корреляция длины и sentiment\n",
        "# 6. Средняя длина слова\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "NLvj2zEzqx4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **2. Предобработка текста**\n",
        "\n",
        "На этом этапе мы создадим функцию для полной предобработки текстовых данных.  \n",
        "\n",
        "- Напишите функцию, выполняющую лемматизацию, удаление стоп-слов, знаков препинания и приведение к нижнему регистру.  \n",
        "- Примените функцию для создания колонки с обработанным текстом.   \n",
        "- Проведите частотный анализ слов и визуализируйте облака слов для позитивных и негативных классов.  \n",
        "- Разделите данные на обучающую, валидационную и тестовую выборки.  \n"
      ],
      "metadata": {
        "id": "a3m6Om41qx4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text,\n",
        "                    language='ru',\n",
        "                    use_lemmatization=True,\n",
        "                    remove_stopwords=True,\n",
        "                    min_word_length=2):\n",
        "    \"\"\"\n",
        "    Полный pipeline предобработки текста.\n",
        "    \"\"\"\n",
        "    # ЗАДАНИЕ: Реализуйте шаги предобработки:\n",
        "    # 1. Приведение к нижнему регистру\n",
        "    # 2. Удаление HTML и URLs\n",
        "    # 3. Удаление спецсимволов\n",
        "    # 4. Удаление лишних пробелов\n",
        "    # 5. Токенизация\n",
        "    # 6. Удаление стоп-слов\n",
        "    # 7. Лемматизация\n",
        "    # 8. Фильтрация по длине слова\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# ЗАДАНИЕ: Примените вашу функцию к столбцу 'text' и создайте новый столбец 'processed_text'.\n",
        "# df['processed_text'] = ...\n",
        "\n",
        "# Анализ результатов предобработки\n",
        "print(\"\\nЭффект предобработки:\")\n",
        "print(f\"Средняя длина до обработки: {df['word_count'].mean():.1f} слов\")\n",
        "print(f\"После полной обработки: {df['processed_text'].str.split().str.len().mean():.1f} слов\")\n",
        "\n",
        "# ЗАДАНИЕ: Проведите частотный анализ слов и создайте облака слов для позитивных и негативных отзывов.\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "5iZ4JMhYqx4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **3. TF-IDF + LogisticRegression**\n",
        "\n",
        "Векторизуем текст с помощью TF-IDF и обучим модель логистической регрессии.\n",
        "\n",
        "- Подберите оптимальные параметры TfidfVectorizer (например, max_features, ngram_range), оценивая F1-score на валидационной выборке.  \n",
        "- Обучите LogisticRegression на лучших TF-IDF признаках.  \n",
        "- Оцените итоговое качество на тестовой выборке. Выведите отчет с метриками и confusion matrix.  \n",
        "- Проанализируйте важность признаков (коэффициенты модели).  \n"
      ],
      "metadata": {
        "id": "XBX4D0GSqx4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение данных на обучающую, валидационную и тестовую выборки\n",
        "X = df['processed_text']\n",
        "y = df['sentiment']\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# ЗАДАНИЕ: Проведите эксперименты с различными параметрами TfidfVectorizer (max_features, ngram_range и т.д.).\n",
        "# Обучите LogisticRegression на каждой конфигурации и выберите лучшую по метрике F1 на валидационной выборке.\n",
        "# tfidf_params = [...]\n",
        "# for params in tfidf_params:\n",
        "#     ...\n",
        "\n",
        "# Финальная оценка лучшей модели на тестовой выборке\n",
        "# best_vectorizer = ...\n",
        "# best_lr_model = ...\n",
        "# X_test_tfidf = best_vectorizer.transform(X_test)\n",
        "# y_test_pred_tfidf = best_lr_model.predict(X_test_tfidf)\n",
        "\n",
        "# ЗАДАНИЕ: Рассчитайте и выведите метрики (Accuracy, Precision, Recall, F1, ROC_AUC) и confusion matrix.\n",
        "# ...\n",
        "\n",
        "# Анализ важности признаков\n",
        "# ...\n",
        "\n",
        "# Сохранение лучшей модели\n",
        "# with open('models/tfidf_lr.pkl', 'wb') as f:\n",
        "#     pickle.dump(best_lr_model, f)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "m_5lX2_Dqx4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **4. Word2Vec embeddings**\n",
        "\n",
        "Теперь используем Word2Vec для получения векторных представлений текста.\n",
        "\n",
        "- Обучите собственную модель Word2Vec на обучающей выборке. Подберите оптимальные параметры (vector_size, window, sg), оценивая F1-score классификатора на валидации.  \n",
        "- Реализуйте функцию получения вектора документа путем усреднения векторов слов.\n",
        "- Обучите LogisticRegression на полученных векторах.\n",
        "- Оцените качество на тестовой выборке."
      ],
      "metadata": {
        "id": "6A1oQPWXqx4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка данных для Word2Vec\n",
        "tokenized_texts = [text.split() for text in df['processed_text']]\n",
        "\n",
        "# ЗАДАНИЕ: Проведите эксперименты с параметрами Word2Vec (vector_size, window, sg).\n",
        "# Для каждого набора параметров векторизуйте тексты (усредняя векторы слов) и обучите LogisticRegression.\n",
        "# Выберите лучшую модель по F1 на валидации.\n",
        "# w2v_params = [...]\n",
        "# for params in w2v_params:\n",
        "#     ...\n",
        "\n",
        "# Финальная оценка лучшей модели\n",
        "# ...\n",
        "\n",
        "# ЗАДАНИЕ: Рассчитайте метрики и выведите confusion matrix.\n",
        "# ...\n",
        "\n",
        "# Анализ семантических отношений (найти похожие слова)\n",
        "# ...\n",
        "\n",
        "# Сохранение лучшей модели\n",
        "# ..."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "ntdqcEKaqx4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **5. FastText embeddings**\n",
        "\n",
        "Обучим модель FastText и сравним ее с Word2Vec.\n",
        "\n",
        "- Обучите модель FastText.\n",
        "- По аналогии с Word2Vec, получите векторы документов и обучите классификатор.\n",
        "- Оцените качество на тестовой выборке.\n",
        "- Продемонстрируйте преимущество FastText на OOV-словах (словах, отсутствующих в словаре).\n"
      ],
      "metadata": {
        "id": "XuDeW6sPqx4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ЗАДАНИЕ: Обучите модель FastText с параметрами по вашему выбору.\n",
        "# fasttext_model = ...\n",
        "\n",
        "# Векторизация и обучение классификатора\n",
        "# ...\n",
        "\n",
        "# ЗАДАНИЕ: Оцените модель на тестовой выборке (метрики и confusion matrix).\n",
        "# ...\n",
        "\n",
        "# Тест на OOV (out-of-vocabulary) словах и сравнение с Word2Vec\n",
        "# ...\n",
        "\n",
        "# Сохранение модели\n",
        "# ..."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "tSAWRXaZqx4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **6. Отчеты и выводы**\n",
        "### **6.1. Визуализация и анализ**\n",
        "\n",
        "Сравним все полученные модели и визуализируем результаты.\n",
        "\n",
        "- Подготовьте сводную таблицу и/или график со сравнительными метриками всех моделей.\n",
        "- Визуализируйте эмбеддинги с помощью t-SNE.\n",
        "- Проанализируйте ошибки моделей.\n"
      ],
      "metadata": {
        "id": "5t2oxWcmqx4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ЗАДАНИЕ: Создайте сравнительную таблицу и графики для метрик всех моделей.\n",
        "# Постройте общую ROC-кривую.\n",
        "# ...\n",
        "\n",
        "# t-SNE визуализация эмбеддингов\n",
        "# (Используйте эмбеддинги лучшей модели Word2Vec или FastText)\n",
        "# ...\n",
        "\n",
        "# Анализ ошибок\n",
        "# (Найдите примеры текстов, на которых все модели ошибаются)\n",
        "# ..."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "OtohJ5Y7qx4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **6. Отчеты и выводы**\n",
        "### **6.2. Подготовка отчетов**\n",
        "\n",
        "Подготовьте итоговый отчет в формате Markdown.\n",
        "\n",
        "- Проанализируйте ошибки моделей.\n",
        "- Сформулируйте итоговые выводы (5-8 предложений): какой метод показал себя лучше и почему, в чем преимущества и недостатки каждого подхода, какие дальнейшие шаги по улучшению качества можно предпринять."
      ],
      "metadata": {
        "id": "quXpG2SRqx4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ЗАДАНИЕ: Сгенерируйте отчет, включающий описание данных, шаги предобработки,\n",
        "# результаты моделей, сравнительный анализ, выводы и рекомендации.\n",
        "report = f\"\"\"\n",
        "# ОТЧЕТ ПО ДОМАШНЕМУ ЗАДАНИЮ\n",
        "\n",
        "## 1. Описание данных\n",
        "...\n",
        "\n",
        "## 2. Предобработка\n",
        "...\n",
        "\n",
        "... (и так далее)\n",
        "\"\"\"\n",
        "\n",
        "# Сохранение отчета в формате markdown, вы можете использовать также pdf и docx\n",
        "with open('reports/final_report.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(report)\n",
        "print(\"Отчет сохранен в reports/final_report.md\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "LmaolPMuqx4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "## **Дополнительное задание по желанию**\n",
        "\n",
        "За задание дополнительные баллы не ставятся. Оно выполняется по желанию студента."
      ],
      "metadata": {
        "id": "VbScgH9jqx4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Примеры бонусных заданий:\n",
        "# 1. Ансамблирование моделей (усреднение вероятностей).\n",
        "# 2. Кросс-валидация для более надежной оценки.\n",
        "# 3. Использование предобученных эмбеддингов (например, из gensim-data).\n",
        "# 4. Анализ интерпретируемости с LIME.\n",
        "# 5. Загрузку Word2Vec модели из Семинара 1"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "LdwZhvPZqx4o"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}