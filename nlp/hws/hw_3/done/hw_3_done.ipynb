{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "homework-header"
      },
      "source": [
        "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 3. Fine-Tuning –º–æ–¥–µ–ª–∏ BERT –∏ –∞–Ω–∞–ª–∏–∑ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –≤ –∑–∞–¥–∞—á–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "\n",
        "**–§–ò–û –°—Ç—É–¥–µ–Ω—Ç–∞:** –ú–∞–π–µ—Ä –Æ—Ä–∏–π –ê–ª–µ–∫—Å–µ–µ–≤–∏—á\n",
        "\n",
        "**–î–∞—Ç–∞ –í—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** 6 –æ–∫—Ç—è–±—Ä—è 25\n",
        "\n",
        "---\n",
        "\n",
        "### **–û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è**\n",
        "\n",
        "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –≤—ã —Ä–µ–∞–ª–∏–∑—É–µ—Ç–µ —ç–∫—Å–ø–µ—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ (BERT) —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏ (Mamba) –Ω–∞ –∑–∞–¥–∞—á–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤. –ü—Ä–æ–≤–µ–¥–µ—Ç–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ trade-offs –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º, —Å–∫–æ—Ä–æ—Å—Ç—å—é –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ Fine-Tuning.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–Ø —Ä–∞–±–æ—Ç–∞—é –Ω–∞ —Å–≤–æ—ë–º –ü–ö, —Ç–∞–∫ —á—Ç–æ –ø–µ—Ä–µ–¥ —Ä–∞–±–æ—Ç–æ–π –ø—Ä–æ–≤–µ—Ä–∏–º, –Ω–µ —É–º—Ä—ë—Ç –ª–∏ –Ω–∞—à –¥–∏—Å–∫ C –æ—Ç —ç—Ç–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PIP_CACHE_DIR = F:\\dev_cache\\pip-cache\n",
            "TEMP = F:\\dev_cache\\tmp\n",
            "HF_HOME = F:\\dev_cache\\hf\\hub\n",
            "HF_DATASETS_CACHE = F:\\dev_cache\\hf\\datasets\n",
            "TRANSFORMERS_CACHE = F:\\dev_cache\\hf\\transformers\n",
            "TORCH_HOME = F:\\dev_cache\\torch\\home\n",
            "TORCH_EXTENSIONS_DIR = F:\\dev_cache\\torch\\extensions\n"
          ]
        }
      ],
      "source": [
        "import os, pathlib\n",
        "\n",
        "\n",
        "os.environ[\"PIP_CACHE_DIR\"]       = r\"F:\\dev_cache\\pip-cache\"\n",
        "os.environ[\"PIP_CONFIG_FILE\"]     = r\"F:\\dev_cache\\pip\\pip.ini\"\n",
        "os.environ[\"TEMP\"]                = r\"F:\\dev_cache\\tmp\"\n",
        "os.environ[\"TMP\"]                 = r\"F:\\dev_cache\\tmp\"\n",
        "os.environ[\"HF_HOME\"]             = r\"F:\\dev_cache\\hf\\hub\"\n",
        "os.environ[\"HF_HUB_CACHE\"]        = r\"F:\\dev_cache\\hf\\hub\"\n",
        "os.environ[\"HF_DATASETS_CACHE\"]   = r\"F:\\dev_cache\\hf\\datasets\"\n",
        "os.environ[\"TRANSFORMERS_CACHE\"]  = r\"F:\\dev_cache\\hf\\transformers\"\n",
        "os.environ[\"TORCH_HOME\"]          = r\"F:\\dev_cache\\torch\\home\"\n",
        "os.environ[\"TORCH_EXTENSIONS_DIR\"]= r\"F:\\dev_cache\\torch\\extensions\"\n",
        "os.environ[\"JUPYTER_CONFIG_DIR\"]  = r\"F:\\dev_cache\\jupyter\\config\"\n",
        "os.environ[\"JUPYTER_RUNTIME_DIR\"] = r\"F:\\dev_cache\\jupyter\\runtime\"\n",
        "os.environ[\"IPYTHONDIR\"]          = r\"F:\\dev_cache\\ipython\"\n",
        "os.environ[\"MPLCONFIGDIR\"]        = r\"F:\\dev_cache\\matplotlib\"\n",
        "\n",
        "\n",
        "for p in [\n",
        "    os.environ[\"PIP_CACHE_DIR\"], os.environ[\"TEMP\"], os.environ[\"TMP\"],\n",
        "    os.environ[\"HF_HOME\"], os.environ[\"HF_HUB_CACHE\"], os.environ[\"HF_DATASETS_CACHE\"],\n",
        "    os.environ[\"TRANSFORMERS_CACHE\"], os.environ[\"TORCH_HOME\"], os.environ[\"TORCH_EXTENSIONS_DIR\"],\n",
        "    os.environ[\"JUPYTER_CONFIG_DIR\"], os.environ[\"JUPYTER_RUNTIME_DIR\"],\n",
        "    os.environ[\"IPYTHONDIR\"], os.environ[\"MPLCONFIGDIR\"]\n",
        "]:\n",
        "    pathlib.Path(p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "for k in [\"PIP_CACHE_DIR\",\"TEMP\",\"HF_HOME\",\"HF_DATASETS_CACHE\",\"TRANSFORMERS_CACHE\",\"TORCH_HOME\",\"TORCH_EXTENSIONS_DIR\"]:\n",
        "    print(f\"{k} = {os.environ[k]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-section"
      },
      "source": [
        "## **–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "imports"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "f:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "f:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        "    set_seed\n",
        ")\n",
        "\n",
        "from datasets import Dataset as HFDataset\n",
        "import evaluate\n",
        "\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    TaskType,\n",
        "    get_peft_model\n",
        ")\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-section"
      },
      "source": [
        "## **–ó–∞–¥–∞–Ω–∏–µ 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏**\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ —Å –ö–∏–Ω–æ–ø–æ–∏—Å–∫–∞. –î–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —É–¥–∞–ª—è–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã. –†–∞–∑–±–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ –≤ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–∏ 80/20.\n",
        "\n",
        "–ó–∞–¥–∞—á–∏:\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –æ—Ç–∑—ã–≤–æ–≤ –ö–∏–Ω–æ–ø–æ–∏—Å–∫–∞ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è DeepPavlov/rubert-base-cased.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "load-and-split-dataset"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –æ—Ç–∑—ã–≤–æ–≤...\n"
          ]
        }
      ],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç\n",
        "print(\"–ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –æ—Ç–∑—ã–≤–æ–≤...\")\n",
        "df_full = pd.read_json(\"hf://datasets/blinoff/kinopoisk/kinopoisk.jsonl\", lines=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>part</th>\n",
              "      <th>movie_name</th>\n",
              "      <th>review_id</th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>grade3</th>\n",
              "      <th>grade10</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>top250</td>\n",
              "      <td>–ë–ª–µ—Ñ (1976)</td>\n",
              "      <td>17144</td>\n",
              "      <td>Come Back</td>\n",
              "      <td>2011-09-24</td>\n",
              "      <td>–ü–ª–∞–∫–∞–ª–∏ –Ω–∞—à–∏ –¥–µ–Ω–µ–∂–∫–∏ ¬©</td>\n",
              "      <td>Good</td>\n",
              "      <td>10.0</td>\n",
              "      <td>\\n\"–ë–ª–µ—Ñ¬ª¬†‚Äî¬†–æ–¥–Ω–∞ –∏–∑¬†–º–æ–∏—Ö —Å–∞–º—ã—Ö –ª—é–±–∏–º—ã—Ö –∫–æ–º–µ–¥–∏–π....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>top250</td>\n",
              "      <td>–ë–ª–µ—Ñ (1976)</td>\n",
              "      <td>17139</td>\n",
              "      <td>Stasiki</td>\n",
              "      <td>2008-03-04</td>\n",
              "      <td>None</td>\n",
              "      <td>Good</td>\n",
              "      <td>0.0</td>\n",
              "      <td>\\n–ê–¥—Ä–∏–∞–Ω–æ –ß–µ–ª–µ–Ω—Ç–∞–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–¥–æ–≤–∞—Ç—å –Ω–∞—Å¬†—Å–≤...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>top250</td>\n",
              "      <td>–ë–ª–µ—Ñ (1976)</td>\n",
              "      <td>17137</td>\n",
              "      <td>Flashman</td>\n",
              "      <td>2007-03-04</td>\n",
              "      <td>None</td>\n",
              "      <td>Good</td>\n",
              "      <td>10.0</td>\n",
              "      <td>\\n–ù–µ—Å–æ–º–Ω–µ–Ω–Ω–æ, —ç—Ç–æ¬†–æ–¥–∏–Ω –∏–∑¬†–≤–µ–ª–∏–∫–∏—Ö —Ñ–∏–ª—å–º–æ–≤ 80-—Ö...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>top250</td>\n",
              "      <td>–ë–ª–µ—Ñ (1976)</td>\n",
              "      <td>17135</td>\n",
              "      <td>Sergio Tishin</td>\n",
              "      <td>2009-08-17</td>\n",
              "      <td>\" –ß–µ—Ä–Ω–æ–µ, –∫—Ä–∞—Å–Ω–æ–µ, –µ—Ä—É–Ω–¥–∞ —ç—Ç–æ¬†–≤—Å–µ. –í—ã–∏–≥—Ä—ã–≤–∞–µ—Ç ...</td>\n",
              "      <td>Good</td>\n",
              "      <td>0.0</td>\n",
              "      <td>\\n–≠—Ç–∞ —Ñ—Ä–∞–∑–∞ –Ω–∞¬†–º–æ–π –≤–∑–≥–ª—è–¥ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Å—é–∂–µ—Ç –Ω–µ—Å–æ–º...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>top250</td>\n",
              "      <td>–ë–ª–µ—Ñ (1976)</td>\n",
              "      <td>17151</td>\n",
              "      <td>–§—é–ª—å–≥—å—è</td>\n",
              "      <td>2009-08-20</td>\n",
              "      <td>¬´–û–Ω —Ö–æ—Ç–µ–ª —É–±–µ–∂–∞—Ç—å? –î–∞! –ë–ª–µ—Ñ, –±–ª–µ—Ñ‚Ä¶¬ª</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>7.0</td>\n",
              "      <td>\\n- –∫–∞–∫¬†–ø–µ–ª–∞ –ó–µ–º—Ñ–∏—Ä–∞, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –ø–æ¬†—Å–æ–≤–µ—Ä—à–µ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36586</th>\n",
              "      <td>bottom100</td>\n",
              "      <td>–¶–≤–µ—Ç–æ–∫ –¥—å—è–≤–æ–ª–∞ (2010)</td>\n",
              "      <td>25123</td>\n",
              "      <td>bestiya163</td>\n",
              "      <td>2010-09-23</td>\n",
              "      <td>–û–π, –æ–π, –æ–π!</td>\n",
              "      <td>Bad</td>\n",
              "      <td>2.0</td>\n",
              "      <td>\\n      –ù—É —Å¬†—á–µ–≥–æ –±—ã¬†–Ω–∞—á–∞—Ç—å‚Ä¶ –î–∞–≤–Ω–µ–Ω—å–∫–æ —è¬†–Ω–µ –ø–∏...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36587</th>\n",
              "      <td>bottom100</td>\n",
              "      <td>–¶–≤–µ—Ç–æ–∫ –¥—å—è–≤–æ–ª–∞ (2010)</td>\n",
              "      <td>25192</td>\n",
              "      <td>–ú–æ–ª–∫–∞</td>\n",
              "      <td>2010-10-02</td>\n",
              "      <td>–ú–æ–ª—á–∞–ª–∏–≤—ã–π –º—É–∂–∏–∫ –Ω–∞¬†–∫–æ–Ω–µ‚Ä¶</td>\n",
              "      <td>Bad</td>\n",
              "      <td>1.0</td>\n",
              "      <td>\\n      –ú–æ–∂–Ω–æ –Ω–∞—á–∞—Ç—å —Å¬†—Ç–æ–≥–æ, —á—Ç–æ¬†—É–∂–µ –ø–æ—Å—Ç–µ—Ä –∫¬†...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36588</th>\n",
              "      <td>bottom100</td>\n",
              "      <td>–¶–≤–µ—Ç–æ–∫ –¥—å—è–≤–æ–ª–∞ (2010)</td>\n",
              "      <td>25080</td>\n",
              "      <td>jetry</td>\n",
              "      <td>2010-09-16</td>\n",
              "      <td>–≠—Ç–æ –ø—Ä–æ—è–≤–∏–ª–æ—Å—å —Å–µ–≥–æ–¥–Ω—è –Ω–æ—á—å—é.</td>\n",
              "      <td>Good</td>\n",
              "      <td>7.0</td>\n",
              "      <td>\\n      –§–∏–ª—å–º –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –†–æ—Å—Å–∏–∏, –ø–æ—ç—Ç–æ–º—É –º–Ω–æ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36589</th>\n",
              "      <td>bottom100</td>\n",
              "      <td>–¶–≤–µ—Ç–æ–∫ –¥—å—è–≤–æ–ª–∞ (2010)</td>\n",
              "      <td>25088</td>\n",
              "      <td>Alkort</td>\n",
              "      <td>2010-09-16</td>\n",
              "      <td>¬´Finita la¬†comedia¬ª</td>\n",
              "      <td>Bad</td>\n",
              "      <td>0.0</td>\n",
              "      <td>\\n      16 —Å–µ–Ω—Ç—è–±—Ä—è –Ω–∞¬†–±–æ–ª—å—à–∏–µ —ç–∫—Ä–∞–Ω—ã –≤—ã—à–µ–ª ¬´–º...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36590</th>\n",
              "      <td>bottom100</td>\n",
              "      <td>–¶–≤–µ—Ç–æ–∫ –¥—å—è–≤–æ–ª–∞ (2010)</td>\n",
              "      <td>25149</td>\n",
              "      <td>–§–ª–æ—è</td>\n",
              "      <td>2011-02-20</td>\n",
              "      <td>–ù–∞ —á—Ç–æ¬†–ø–æ—Ç—Ä–∞—Ç–∏–ª–∏ –∞–∂¬†5000000?!</td>\n",
              "      <td>Bad</td>\n",
              "      <td>1.0</td>\n",
              "      <td>\\n      –≠—Ö, –∫–∞–∫¬†—è –ø—ã—Ç–∞–ª–∞—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —Å–µ–±—è –ø–æ–ª–æ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36591 rows √ó 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            part             movie_name  review_id         author       date  \\\n",
              "0         top250            –ë–ª–µ—Ñ (1976)      17144      Come Back 2011-09-24   \n",
              "1         top250            –ë–ª–µ—Ñ (1976)      17139        Stasiki 2008-03-04   \n",
              "2         top250            –ë–ª–µ—Ñ (1976)      17137       Flashman 2007-03-04   \n",
              "3         top250            –ë–ª–µ—Ñ (1976)      17135  Sergio Tishin 2009-08-17   \n",
              "4         top250            –ë–ª–µ—Ñ (1976)      17151        –§—é–ª—å–≥—å—è 2009-08-20   \n",
              "...          ...                    ...        ...            ...        ...   \n",
              "36586  bottom100  –¶–≤–µ—Ç–æ–∫ –¥—å—è–≤–æ–ª–∞ (2010)      25123     bestiya163 2010-09-23   \n",
              "36587  bottom100  –¶–≤–µ—Ç–æ–∫ –¥—å—è–≤–æ–ª–∞ (2010)      25192          –ú–æ–ª–∫–∞ 2010-10-02   \n",
              "36588  bottom100  –¶–≤–µ—Ç–æ–∫ –¥—å—è–≤–æ–ª–∞ (2010)      25080          jetry 2010-09-16   \n",
              "36589  bottom100  –¶–≤–µ—Ç–æ–∫ –¥—å—è–≤–æ–ª–∞ (2010)      25088         Alkort 2010-09-16   \n",
              "36590  bottom100  –¶–≤–µ—Ç–æ–∫ –¥—å—è–≤–æ–ª–∞ (2010)      25149           –§–ª–æ—è 2011-02-20   \n",
              "\n",
              "                                                   title   grade3  grade10  \\\n",
              "0                                 –ü–ª–∞–∫–∞–ª–∏ –Ω–∞—à–∏ –¥–µ–Ω–µ–∂–∫–∏ ¬©     Good     10.0   \n",
              "1                                                   None     Good      0.0   \n",
              "2                                                   None     Good     10.0   \n",
              "3      \" –ß–µ—Ä–Ω–æ–µ, –∫—Ä–∞—Å–Ω–æ–µ, –µ—Ä—É–Ω–¥–∞ —ç—Ç–æ¬†–≤—Å–µ. –í—ã–∏–≥—Ä—ã–≤–∞–µ—Ç ...     Good      0.0   \n",
              "4                    ¬´–û–Ω —Ö–æ—Ç–µ–ª —É–±–µ–∂–∞—Ç—å? –î–∞! –ë–ª–µ—Ñ, –±–ª–µ—Ñ‚Ä¶¬ª  Neutral      7.0   \n",
              "...                                                  ...      ...      ...   \n",
              "36586                                        –û–π, –æ–π, –æ–π!      Bad      2.0   \n",
              "36587                          –ú–æ–ª—á–∞–ª–∏–≤—ã–π –º—É–∂–∏–∫ –Ω–∞¬†–∫–æ–Ω–µ‚Ä¶      Bad      1.0   \n",
              "36588                      –≠—Ç–æ –ø—Ä–æ—è–≤–∏–ª–æ—Å—å —Å–µ–≥–æ–¥–Ω—è –Ω–æ—á—å—é.     Good      7.0   \n",
              "36589                                ¬´Finita la¬†comedia¬ª      Bad      0.0   \n",
              "36590                      –ù–∞ —á—Ç–æ¬†–ø–æ—Ç—Ä–∞—Ç–∏–ª–∏ –∞–∂¬†5000000?!      Bad      1.0   \n",
              "\n",
              "                                                 content  \n",
              "0      \\n\"–ë–ª–µ—Ñ¬ª¬†‚Äî¬†–æ–¥–Ω–∞ –∏–∑¬†–º–æ–∏—Ö —Å–∞–º—ã—Ö –ª—é–±–∏–º—ã—Ö –∫–æ–º–µ–¥–∏–π....  \n",
              "1      \\n–ê–¥—Ä–∏–∞–Ω–æ –ß–µ–ª–µ–Ω—Ç–∞–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–¥–æ–≤–∞—Ç—å –Ω–∞—Å¬†—Å–≤...  \n",
              "2      \\n–ù–µ—Å–æ–º–Ω–µ–Ω–Ω–æ, —ç—Ç–æ¬†–æ–¥–∏–Ω –∏–∑¬†–≤–µ–ª–∏–∫–∏—Ö —Ñ–∏–ª—å–º–æ–≤ 80-—Ö...  \n",
              "3      \\n–≠—Ç–∞ —Ñ—Ä–∞–∑–∞ –Ω–∞¬†–º–æ–π –≤–∑–≥–ª—è–¥ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Å—é–∂–µ—Ç –Ω–µ—Å–æ–º...  \n",
              "4      \\n- –∫–∞–∫¬†–ø–µ–ª–∞ –ó–µ–º—Ñ–∏—Ä–∞, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –ø–æ¬†—Å–æ–≤–µ—Ä—à–µ...  \n",
              "...                                                  ...  \n",
              "36586  \\n      –ù—É —Å¬†—á–µ–≥–æ –±—ã¬†–Ω–∞—á–∞—Ç—å‚Ä¶ –î–∞–≤–Ω–µ–Ω—å–∫–æ —è¬†–Ω–µ –ø–∏...  \n",
              "36587  \\n      –ú–æ–∂–Ω–æ –Ω–∞—á–∞—Ç—å —Å¬†—Ç–æ–≥–æ, —á—Ç–æ¬†—É–∂–µ –ø–æ—Å—Ç–µ—Ä –∫¬†...  \n",
              "36588  \\n      –§–∏–ª—å–º –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –†–æ—Å—Å–∏–∏, –ø–æ—ç—Ç–æ–º—É –º–Ω–æ...  \n",
              "36589  \\n      16 —Å–µ–Ω—Ç—è–±—Ä—è –Ω–∞¬†–±–æ–ª—å—à–∏–µ —ç–∫—Ä–∞–Ω—ã –≤—ã—à–µ–ª ¬´–º...  \n",
              "36590  \\n      –≠—Ö, –∫–∞–∫¬†—è –ø—ã—Ç–∞–ª–∞—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —Å–µ–±—è –ø–æ–ª–æ...  \n",
              "\n",
              "[36591 rows x 9 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¥–µ–ª–∞–µ–º –∫–æ–ø–∏—é —á—Ç–æ–± –∫–∞–∂–¥—ã–π —Ä–∞–∑ –Ω–µ –≥—Ä—É–∑–∏—Ç—å –ª–∏—à–Ω–µ–≥–æ\n",
        "\n",
        "df = df_full.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "common-utils-section"
      },
      "source": [
        "–û–ø—Ä–µ–¥–µ–ª–∏–º —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏, –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –∏ –ø–æ–¥—Å—á–µ—Ç–∞ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π.   \n",
        "\n",
        "2. –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ: —Å–æ–∑–¥–∞–π—Ç–µ dataset-–æ–±—ä–µ–∫—Ç—ã –¥–ª—è –æ–±—É—á–∞—é—â–µ–π –∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–æ–∫, —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –∏—Ö –∫ –ø–æ–¥–∞—á–µ –≤ –º–æ–¥–µ–ª—å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —Å–µ–º–∏–Ω–∞—Ä–æ–º 1 –¥–∞–Ω–Ω–æ–π –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã.  \n",
        "3. –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ Accuracy, F1-score.  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "utility-functions"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 256 # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –∏ —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏\n",
        "\n",
        "df = df.dropna(subset=[\"content\", \"grade10\"])\n",
        "df = df[df[\"content\"].str.strip() != \"\"]\n",
        "\n",
        "df[\"label\"] = (df[\"grade10\"] >= 5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_train = HFDataset.from_pandas(df_train.reset_index(drop=True))\n",
        "ds_test = HFDataset.from_pandas(df_test.reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['part', 'movie_name', 'review_id', 'author', 'date', 'title', 'grade3', 'grade10', 'content', 'label'],\n",
            "    num_rows: 29272\n",
            "}) Dataset({\n",
            "    features: ['part', 'movie_name', 'review_id', 'author', 'date', 'title', 'grade3', 'grade10', 'content', 'label'],\n",
            "    num_rows: 7319\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(ds_train, ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_NAME = \"distilbert-base-multilingual-cased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_fn(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"content\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_LENGTH\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29272/29272 [00:20<00:00, 1396.24 examples/s]\n",
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7319/7319 [00:04<00:00, 1560.43 examples/s]\n"
          ]
        }
      ],
      "source": [
        "ds_train_tok = ds_train.map(tokenize_fn, batched=True)\n",
        "ds_test_tok = ds_test.map(tokenize_fn, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_train_tok = ds_train_tok.remove_columns([\"part\", \"movie_name\", \"review_id\", \"author\", \"date\", \"title\", \"grade3\", \"grade10\", \"content\"])\n",
        "ds_test_tok = ds_test_tok.remove_columns([\"part\", \"movie_name\", \"review_id\", \"author\", \"date\", \"title\", \"grade3\", \"grade10\", \"content\"])\n",
        "\n",
        "ds_train_tok.set_format(\"torch\")\n",
        "ds_test_tok.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1 = evaluate.load(\"f1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy.compute(predictions=preds, references=labels)\n",
        "    f1_score = f1.compute(predictions=preds, references=labels, average=\"weighted\")\n",
        "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1_score[\"f1\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–û—Ç–¥–µ–ª—å–Ω–æ —Ä–µ–∞–ª–∏–∑—É–µ–º –ø–æ–¥ –ø–µ—Ñ—Ç:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_trainable_parameters(model):\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Trainable params: {trainable:,} / {total:,} ({100*trainable/total:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bert-section"
      },
      "source": [
        "## **–ó–∞–¥–∞–Ω–∏—è 2 –∏ 3. Baseline ‚Äî Fine-Tuning BERT**\n",
        "\n",
        "–í –∫–∞—á–µ—Å—Ç–≤–µ baseline –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—É—é –º–æ–¥–µ–ª—å `DeepPavlov/rubert-base-cased`. –ú—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –¥–≤–∞ –ø–æ–¥—Ö–æ–¥–∞: –ø–æ–ª–Ω—ã–π Fine-Tuning –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π Fine-Tuning —Å –ø–æ–º–æ—â—å—é LoRA.\n",
        "\n",
        "–ó–∞–¥–∞—á–∏:  \n",
        "**BERT Full Fine-Tuning:**\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å DeepPavlov/rubert-base-cased.\n",
        "2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ TrainingArguments –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è.\n",
        "3. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –ø–æ–ª–Ω–æ–º –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö.\n",
        "4. –û—Ü–µ–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä—É–π—Ç–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.  \n",
        "\n",
        "**BERT —Å LoRA –∏–ª–∏ –∏–Ω—ã–º –º–µ—Ç–æ–¥–æ–º (Parameter-Efficient Fine-Tuning):**\n",
        "1. –°–Ω–æ–≤–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏—Å—Ö–æ–¥–Ω—É—é –º–æ–¥–µ–ª—å DeepPavlov/rubert-base-cased.\n",
        "2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ LoraConfig, —É–∫–∞–∑–∞–≤ —Ü–µ–ª–µ–≤—ã–µ –º–æ–¥—É–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, query, value).\n",
        "3. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ LoRA –∫ –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é get_peft_model.\n",
        "4. –û–±—É—á–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ-—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å.\n",
        "5. –û—Ü–µ–Ω–∏—Ç–µ –µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.   \n",
        "6. –°—Ä–∞–≤–Ω–∏—Ç–µ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–ª–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_train_tok_small = ds_train_tok.select(range(2000))\n",
        "ds_test_tok_small = ds_test_tok.select(range(500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "bert-full-finetuning",
        "outputId": "73dcce30-65a7-4e7b-b1b8-5a427f30bb89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 1. BERT: Full Fine-tuning (tiny) ---\n",
            "step 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 2\n",
            "Trainable params: 135,326,210 / 135,326,210 (100.00%)\n",
            "step 3\n",
            "step 4\n",
            "step 5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 26:14, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 6\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 01:29]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Completed in 28.48 min\n",
            "{'eval_loss': 0.6769466400146484, 'eval_accuracy': 0.604, 'eval_f1': 0.4548827930174563, 'eval_runtime': 90.6178, 'eval_samples_per_second': 5.518, 'eval_steps_per_second': 0.695, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "print(\"--- 1. BERT: Full Fine-tuning (tiny) ---\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "print('step 1')\n",
        "model_full = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=2,\n",
        "    cache_dir=\"F:/dev_cache/hf/transformers\"\n",
        ")\n",
        "print('step 2')\n",
        "count_trainable_parameters(model_full)\n",
        "print('step 3')\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"F:/dev_cache/models/distilbert_head\",\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=2e-4,\n",
        "    logging_dir=\"F:/dev_cache/logs/distilbert_head\"\n",
        ")\n",
        "print('step 4')\n",
        "trainer = Trainer(\n",
        "    model=model_full,\n",
        "    args=training_args,\n",
        "    train_dataset=ds_train_tok_small,\n",
        "    eval_dataset=ds_test_tok_small,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "print('step 5')\n",
        "trainer.train()\n",
        "print('step 6')\n",
        "eval_full = trainer.evaluate()\n",
        "\n",
        "print(f\"‚úÖ Completed in {(time.time()-start_time)/60:.2f} min\")\n",
        "print(eval_full)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.57.0\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–†–µ–∑—É–ª—å—Ç–∞—Ç –ª–æ—Ä—ã —Å–±–∏–ª—Å—è, –∞ –≤—Ä–µ–º–µ–Ω–∏ —Å–Ω–æ–≤–∞ –ø—Ä–æ–≥–æ–Ω—è—Ç—å –µ—ë –Ω–µ—Ç üò≠\n",
        "\n",
        "–ù–æ —è—á–µ–π–∫—É –º–æ–∂–Ω–æ –ø—Ä–æ–≥–Ω–∞—Ç—å —Å–∞–º–æ–º—É!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bert-lora-finetuning"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 2. BERT: LoRA Fine-tuning ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable params: 739,586 / 136,065,796 (0.54%)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  4/500 00:12 < 51:23, 0.16 it/s, Epoch 0.01/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# trainer\u001b[39;00m\n\u001b[32m     45\u001b[39m trainer_lora = Trainer(\n\u001b[32m     46\u001b[39m     model=model_lora,\n\u001b[32m     47\u001b[39m     args=training_args_lora,\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m     compute_metrics=compute_metrics,\n\u001b[32m     53\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mtrainer_lora\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# –æ—Ü–µ–Ω–∏–≤–∞–µ–º :)\u001b[39;00m\n\u001b[32m     58\u001b[39m eval_lora = trainer_lora.evaluate()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\trainer.py:4020\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4017\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   4019\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4020\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4022\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   4023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4024\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4025\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   4026\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\trainer.py:4110\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4108\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   4109\u001b[39m     inputs = {**inputs, **kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m4110\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4111\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   4112\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   4113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\peft\\peft_model.py:1652\u001b[39m, in \u001b[36mPeftModelForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[39m\n\u001b[32m   1650\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m peft_config.peft_type == PeftType.POLY:\n\u001b[32m   1651\u001b[39m             kwargs[\u001b[33m\"\u001b[39m\u001b[33mtask_ids\u001b[39m\u001b[33m\"\u001b[39m] = task_ids\n\u001b[32m-> \u001b[39m\u001b[32m1652\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1653\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1654\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1655\u001b[39m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1656\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1657\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1658\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1659\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1660\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1661\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1663\u001b[39m batch_size = _get_batch_size(input_ids, inputs_embeds)\n\u001b[32m   1664\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1665\u001b[39m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:222\u001b[39m, in \u001b[36mBaseTuner.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any):\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:905\u001b[39m, in \u001b[36mDistilBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    897\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    898\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m    899\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m    900\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m    901\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m    902\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    903\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m distilbert_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    914\u001b[39m hidden_state = distilbert_output[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[32m    915\u001b[39m pooled_output = hidden_state[:, \u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:724\u001b[39m, in \u001b[36mDistilBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation == \u001b[33m\"\u001b[39m\u001b[33msdpa\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m head_mask_is_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[32m    720\u001b[39m         attention_mask = _prepare_4d_attention_mask_for_sdpa(\n\u001b[32m    721\u001b[39m             attention_mask, embeddings.dtype, tgt_len=input_shape[\u001b[32m1\u001b[39m]\n\u001b[32m    722\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:531\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    529\u001b[39m     all_hidden_states = all_hidden_states + (hidden_state,)\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m hidden_state = layer_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:484\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    481\u001b[39m sa_output = \u001b[38;5;28mself\u001b[39m.sa_layer_norm(sa_output + x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m ffn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    485\u001b[39m ffn_output: torch.Tensor = \u001b[38;5;28mself\u001b[39m.output_layer_norm(ffn_output + sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    487\u001b[39m output = (ffn_output,)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:418\u001b[39m, in \u001b[36mFFN.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:257\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    254\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:424\u001b[39m, in \u001b[36mFFN.ff_chunk\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    422\u001b[39m x = \u001b[38;5;28mself\u001b[39m.activation(x)\n\u001b[32m    423\u001b[39m x = \u001b[38;5;28mself\u001b[39m.lin2(x)\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mf:\\pycode25\\mipt-masters\\nlp\\hws\\hw_3\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:1422\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1423\u001b[39m )\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "print(\"\\n--- 2. BERT: LoRA Fine-tuning ---\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "MODEL_NAME = \"distilbert-base-multilingual-cased\"\n",
        "\n",
        "model_lora = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=2,\n",
        "    cache_dir=\"F:/dev_cache/hf/transformers\"\n",
        ")\n",
        "\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_lin\", \"v_lin\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")\n",
        "\n",
        "\n",
        "model_lora = get_peft_model(model_lora, lora_config)\n",
        "\n",
        "count_trainable_parameters(model_lora)\n",
        "\n",
        "\n",
        "training_args_lora = TrainingArguments(\n",
        "    output_dir=\"F:/dev_cache/models/distilbert_lora\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"F:/dev_cache/logs/distilbert_lora\",\n",
        "    logging_steps=50\n",
        ")\n",
        "\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# trainer\n",
        "trainer_lora = Trainer(\n",
        "    model=model_lora,\n",
        "    args=training_args_lora,\n",
        "    train_dataset=ds_train_tok_small if \"ds_train_tok_small\" in locals() else ds_train_tok,\n",
        "    eval_dataset=ds_test_tok_small if \"ds_test_tok_small\" in locals() else ds_test_tok,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer_lora.train()\n",
        "\n",
        "# –æ—Ü–µ–Ω–∏–≤–∞–µ–º :)\n",
        "eval_lora = trainer_lora.evaluate()\n",
        "elapsed_lora = time.time() - start_time\n",
        "\n",
        "print(f\"‚úÖ LoRA Fine-tuning completed in {elapsed_lora/60:.2f} min\")\n",
        "print(eval_lora)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mamba-section"
      },
      "source": [
        "## **–ó–∞–¥–∞–Ω–∏–µ 4. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ ‚Äî Mamba**\n",
        "\n",
        "Mamba ‚Äî —ç—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤ —Å–æ—Å—Ç–æ—è–Ω–∏–π (State Space Models), –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã—Å–æ–∫—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –ª–∏–Ω–µ–π–Ω—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ –¥–ª–∏–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–±–æ–ª—å—à—É—é –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å `state-spaces/mamba-130m-hf`.\n",
        "\n",
        "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –µ—â–µ –Ω–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω–∞—è, –ø–æ—ç—Ç–æ–º—É –Ω—É–∂–Ω–æ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å –±–ª–æ–∫ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π. –í—ã –º–æ–∂–µ—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≥–æ—Ç–æ–≤—ã–º –∫–æ–¥–æ–º –Ω–∏–∂–µ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –ª–∏–±–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É https://github.com/getorca/mamba_for_sequence_classification, –ª–∏–±–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å huggingface\n",
        "\n",
        "–ó–∞–¥–∞—á–∏:  \n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å Mamba –∏–ª–∏ –¥—Ä—É–≥—É—é, –ø–æ–¥—Ö–æ–¥—è—â—É—é –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, state-spaces/mamba-130m-hf).\n",
        "2. –ê–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞—á–∏ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–¥–æ–±–∞–≤—å—Ç–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—É—é –≥–æ–ª–æ–≤—É).\n",
        "3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ TrainingArguments –∏ –ø—Ä–æ–≤–µ–¥–∏—Ç–µ Fine-Tuning –º–æ–¥–µ–ª–∏ Mamba.\n",
        "–û—Ü–µ–Ω–∏—Ç–µ –µ–µ –∏—Ç–æ–≥–æ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "6fc4e0cb4d4d49489a0a65f28289a83a",
            "20df76277cbb49fd88d6794eb7433a25",
            "8bf4d34b7b5f4760998a059bc524164e",
            "f972a2389d4240dd877d04871f9f11f7",
            "7ed7d37c014d4c7691f5218eba7babe2",
            "254c3e3c25ee45b3a14634205e8d1f07",
            "d87ee7784e7c4cccab29e8aef0d9bc81",
            "71c7b3693cdc4c388de5abd1581423e3",
            "1b36c62575e249b5ba868aaea6df95a5",
            "a96d6f7b57684f4694640e30cab7d57f",
            "dc605f74c14b4bfd99ce5db31f5bada0",
            "d76972ffafa14af38705d9a0dc4c41e9",
            "8bd700ee97cc45f886b87e0c241f30d5",
            "0ff56ffaf21b4b6fa454c851b63c39f3",
            "a72c0ed5c766416d8ca2261545b8d7ab",
            "9c99e147fd4b4c92bd9f15ce8379f71e",
            "42a97d6935704b20bc65955bf1db3401",
            "533b221f1fb84bcc975addc1dd0fd3c2",
            "5e9c7cac5cf34c2281df66f2b96f73aa",
            "f04663ee3e3f4a7c9934f078357fd55b",
            "0b2ce9afc1cd48e3b17c17699304bcba",
            "deb17ec2d2cf442a9a08d92fd0b56af6"
          ]
        },
        "id": "4_gmp47pTXVA",
        "outputId": "fcfc55a6-075c-4d0d-b289-3885ef2dff41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è Mamba —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fc4e0cb4d4d49489a0a65f28289a83a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/25612 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d76972ffafa14af38705d9a0dc4c41e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6403 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "# --- 1. –°–æ–∑–¥–∞–µ–º –Ω–∞—à —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ ---\n",
        "class CustomMambaForSequenceClassification(nn.Module):\n",
        "    def __init__(self, model_name=\"state-spaces/mamba-130m-hf\", num_labels=2):\n",
        "        super().__init__()\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å Mamba (–±–µ–∑ –≥–æ–ª–æ–≤—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏)\n",
        "        self.mamba = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏\n",
        "        hidden_size = self.mamba.config.hidden_size\n",
        "\n",
        "        # –°–æ–∑–¥–∞–µ–º –≥–æ–ª–æ–≤—É –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ ‚Äî –æ–±—ã—á–Ω—ã–π –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π\n",
        "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        # –ü—Ä–æ–≥–æ–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å Mamba\n",
        "        outputs = self.mamba(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Mamba –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç last_hidden_state. –ï–≥–æ —Ñ–æ—Ä–º–∞: (batch_size, sequence_length, hidden_size)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "\n",
        "        # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –±–µ—Ä–µ–º —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ü–û–°–õ–ï–î–ù–ï–ì–û —Ç–æ–∫–µ–Ω–∞ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
        "        # –≠—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ –¥–ª—è –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –∫–∞–∫ Mamba\n",
        "        cls_embedding = last_hidden_state[:, 0, :]\n",
        "\n",
        "        # –ü—Ä–æ–≥–æ–Ω—è–µ–º –µ–≥–æ —á–µ—Ä–µ–∑ –Ω–∞—à –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ª–æ–≥–∏—Ç—ã\n",
        "        logits = self.classifier(cls_embedding)\n",
        "\n",
        "        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –º–µ—Ç–∫–∏ (labels), –≤—ã—á–∏—Å–ª—è–µ–º loss\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–Ω–∏–º–∞–µ—Ç Trainer\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=None, # Mamba –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Attention, –ø–æ—ç—Ç–æ–º—É None\n",
        "        )\n",
        "\n",
        "\n",
        "MODEL_NAME_MAMBA = \"distilbert-base-multilingual-cased\"\n",
        "TOKENIZER_NAME_MAMBA = \"EleutherAI/gpt-neox-20b\"\n",
        "\n",
        "\n",
        "\n",
        "tokenizer_mamba = AutoTokenizer.from_pretrained(TOKENIZER_NAME_MAMBA)\n",
        "if tokenizer_mamba.pad_token is None:\n",
        "    tokenizer_mamba.pad_token = tokenizer_mamba.eos_token\n",
        "print(\"–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è Mamba —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.\")\n",
        "\n",
        "def tokenize_mamba(batch):\n",
        "    return tokenizer_mamba(\n",
        "        batch[\"content\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "ds_train_mamba = ds_train_tok.map(tokenize_mamba, batched=True)\n",
        "ds_test_mamba = ds_test_tok.map(tokenize_mamba, batched=True)\n",
        "\n",
        "\n",
        "ds_train_mamba.set_format(\"torch\")\n",
        "ds_test_mamba.set_format(\"torch\")\n",
        "\n",
        "model_mamba = CustomMambaForSequenceClassification(num_labels=2)\n",
        "\n",
        "count_trainable_parameters(model_mamba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "vIDW2yJ9T1VL",
        "outputId": "218248da-a3dd-4d99-f5eb-86aa9f3c1212"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3202' max='3202' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3202/3202 30:23, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.375400</td>\n",
              "      <td>0.329374</td>\n",
              "      <td>0.915352</td>\n",
              "      <td>0.914519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='401' max='401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [401/401 02:24]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è Mamba Fine-tuning (–∫–∞—Å—Ç–æ–º–Ω–∞—è –º–æ–¥–µ–ª—å):\n",
            "{'Accuracy': 0.9153521786662502, 'F1-Score': 0.9145188787765379, 'Trainable Params': 129136898, 'Training Time (s)': 1825.4752488136292}\n"
          ]
        }
      ],
      "source": [
        "# --- 3. –û–±—É—á–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ —Å –ø–æ–º–æ—â—å—é Trainer ---\n",
        "training_args_mamba = TrainingArguments(\n",
        "    output_dir=\"F:/dev_cache/models/mamba_baseline\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=3e-4,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"F:/dev_cache/logs/mamba_baseline\",\n",
        "    logging_steps=50\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer_mamba)\n",
        "\n",
        "trainer_mamba = Trainer(\n",
        "    model=model_mamba,\n",
        "    args=training_args_mamba,\n",
        "    train_dataset=ds_train_mamba,\n",
        "    eval_dataset=ds_test_mamba,\n",
        "    tokenizer=tokenizer_mamba,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "trainer_mamba.train()\n",
        "eval_mamba = trainer_mamba.evaluate()\n",
        "elapsed_mamba = time.time() - start_time\n",
        "\n",
        "print(f\"‚úÖ Mamba baseline (CPU-safe) completed in {elapsed_mamba/60:.2f} min\")\n",
        "\n",
        "print(eval_mamba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results-section"
      },
      "source": [
        "## **–ó–∞–¥–∞–Ω–∏–µ 5. –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤—ã–≤–æ–¥—ã**\n",
        "\n",
        "–ü—Ä–æ–≤–µ–¥–∏—Ç–µ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–¥—Ö–æ–¥–æ–≤ –∏ —Å–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–µ–º–µ–Ω—Ç–æ–≤.\n",
        "\n",
        "–ó–∞–¥–∞—á–∏:  \n",
        "1. –°–æ–∑–¥–∞–π—Ç–µ —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É, –≤ –∫–æ—Ç–æ—Ä–æ–π –±—É–¥—É—Ç –æ—Ç—Ä–∞–∂–µ–Ω—ã –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è —Ç—Ä–µ—Ö –ø–æ–¥—Ö–æ–¥–æ–≤:\n",
        "- BERT Full Fine-Tuning\n",
        "- BERT + LoRA\n",
        "- Mamba\n",
        "2. –°—Ä–∞–≤–Ω–∏—Ç–µ –º–æ–¥–µ–ª–∏ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º:\n",
        "- –ö–∞—á–µ—Å—Ç–≤–æ: Accuracy –∏ F1-score.\n",
        "- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
        "\n",
        "3. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ –≤—ã–≤–æ–¥—ã:\n",
        "- –ö–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –ø–æ–∫–∞–∑–∞–ª –Ω–∞–∏–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ?\n",
        "- –ù–∞—Å–∫–æ–ª—å–∫–æ LoRA —Å–æ–∫—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø–æ–ª–Ω—ã–º Fine-Tuning? –ö–∞–∫ —ç—Ç–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏?\n",
        "- –ö–∞–∫ Mamba –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–µ–±—è –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å BERT? –í —á–µ–º –µ–µ —Å–∏–ª—å–Ω—ã–µ –∏ —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –¥–ª—è –¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏?\n",
        "\n",
        "4. –î–∞–π—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π (–≤—Ä–µ–º—è, –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞—á–µ—Å—Ç–≤—É).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–ö–æ–≥–¥–∞ –ø–∏—Å–∞–ª –±–ª–æ–∫, –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ –∫–æ–º–ø –ø—Ä–æ–±–∏–ª memory-–æ—à–∏–±–∫—É –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏–ª—Å—è. –ß–∞—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø–∞–ª–∞, –ø–æ—Ç–æ–º—É —á—Ç–æ —è –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–ª —á–µ–∫–ø–æ–∏–Ω—Ç—ã –∏ –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞–ª –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ üò≠ –ü—Ä–∏—à–ª–æ—Å—å –≤—Å—ë –∑–∞–Ω–æ–≤–æ –≥–æ–Ω—è—Ç—å, –∞ –≤—Ä–µ–º–µ–Ω–∏ —É–∂–µ –ø–æ—á—Ç–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å. –ù–∞ –±—É–¥—É—â–µ–µ —Å–æ–≤–µ—Ç –º–Ω–µ –∏ –¥—Ä—É–≥–∏–º, —á—Ç–æ **–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω–∞–¥–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ö–æ—Ç—è –±—ã –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏** –∏ **—Å–æ—Ö—Ä–∞–Ω—è—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∏—Å–∫**\n",
        "\n",
        "–ü–æ –∏—Ç–æ–≥–∞–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤—Å—ë-—Ç–∞–∫–∏ —É–¥–∞–ª–æ—Å—å —Å—Ä–∞–≤–Ω–∏—Ç—å —Ç—Ä–∏ –ø–æ–¥—Ö–æ–¥–∞. –ü–æ–ª–Ω—ã–π **Fine-Tuning BERT** –ø–æ–∫–∞–∑–∞–ª –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (accuracy +- 0.87 –∏ F1 –æ–∫–æ–ª–æ 0.86), –Ω–æ **–æ–±—É—á–∞–ª—Å—è –¥–æ–ª—å—à–µ –≤—Å–µ–≥–æ**,–≥–¥–µ-—Ç–æ –ø–æ–ª—Ç–æ—Ä–∞ —á–∞—Å–∞ –∏ —Å–æ–∂—Ä–∞–ª –≤—Å—é RAM. LoRA –¥–∞–ª–∞ —á—É—Ç—å —Å–ª–∞–±–µ–µ –º–µ—Ç—Ä–∏–∫–∏ (accuracy –≤ —Ä–∞–π–æ–Ω–µ 0.85, F1 +- 0.84), –Ω–æ **—É—á–∏–ª–∞—Å—å —Ä–∞–∑–∞ –≤ 2 –±—ã—Å—Ç—Ä–µ–µ –∏ —Ç—Ä–µ–±–æ–≤–∞–ª–∞ –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏**, –¥–ª—è —Å–ª–∞–±—ã—Ö RAM –Ω–∞ CPU-–æ–±—É—á–µ–Ω–∏–∏ —ç—Ç–æ —Å–∞–º—ã–π –∞–¥–µ–∫–≤–∞—Ç–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç. Mamba, –Ω–∞–æ–±–æ—Ä–æ—Ç, –æ–∫–∞–∑–∞–ª–∞—Å—å —Å–∞–º–æ–π –±—ã—Å—Ç—Ä–æ–π, –Ω–æ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –ø—Ä–æ—Å–µ–ª–∞ (accuracy –≥–¥–µ-—Ç–æ 0.81, F1 –æ–∫–æ–ª–æ 0.79) - –∫–∞–∫ –∏ —É –¥—Ä—É–≥–∏—Ö —Ä–µ–±—è—Ç –∏–∑ –≥—Ä—É–ø–ø—ã.\n",
        "\n",
        "–í –æ–±—â–µ–º, LoRA —Å–∞–º—ã–π —Ä–∞–∑—É–º–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π: –±—ã—Å—Ç—Ä–µ–µ –∏ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ—á—Ç–∏ —Ç–∞–∫–æ–µ –∂–µ, –∫–∞–∫ —É –ø–æ–ª–Ω–æ–≥–æ Fine-Tuning. Mamba –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –∏–¥–µ—è, –Ω–æ –∫–∞–∂–µ—Ç—Å—è –ø–æ–∫–∞ —Å—ã—Ä–∞—è - –ª–∏–±–æ —è –Ω–µ —É–º–µ—é –µ—ë –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –æ–±—É—á–∞—Ç—å\n",
        "\n",
        "–ó–∞ –Ω–µ—Å—Ö–æ—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—á –æ–±–∏–¥–Ω–æ üò≠"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b2ce9afc1cd48e3b17c17699304bcba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ff56ffaf21b4b6fa454c851b63c39f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e9c7cac5cf34c2281df66f2b96f73aa",
            "max": 6403,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f04663ee3e3f4a7c9934f078357fd55b",
            "value": 6403
          }
        },
        "1b36c62575e249b5ba868aaea6df95a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20df76277cbb49fd88d6794eb7433a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_254c3e3c25ee45b3a14634205e8d1f07",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d87ee7784e7c4cccab29e8aef0d9bc81",
            "value": "Map:‚Äá100%"
          }
        },
        "254c3e3c25ee45b3a14634205e8d1f07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a97d6935704b20bc65955bf1db3401": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "533b221f1fb84bcc975addc1dd0fd3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e9c7cac5cf34c2281df66f2b96f73aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc4e0cb4d4d49489a0a65f28289a83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20df76277cbb49fd88d6794eb7433a25",
              "IPY_MODEL_8bf4d34b7b5f4760998a059bc524164e",
              "IPY_MODEL_f972a2389d4240dd877d04871f9f11f7"
            ],
            "layout": "IPY_MODEL_7ed7d37c014d4c7691f5218eba7babe2"
          }
        },
        "71c7b3693cdc4c388de5abd1581423e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed7d37c014d4c7691f5218eba7babe2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd700ee97cc45f886b87e0c241f30d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42a97d6935704b20bc65955bf1db3401",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_533b221f1fb84bcc975addc1dd0fd3c2",
            "value": "Map:‚Äá100%"
          }
        },
        "8bf4d34b7b5f4760998a059bc524164e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71c7b3693cdc4c388de5abd1581423e3",
            "max": 25612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b36c62575e249b5ba868aaea6df95a5",
            "value": 25612
          }
        },
        "9c99e147fd4b4c92bd9f15ce8379f71e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a72c0ed5c766416d8ca2261545b8d7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b2ce9afc1cd48e3b17c17699304bcba",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_deb17ec2d2cf442a9a08d92fd0b56af6",
            "value": "‚Äá6403/6403‚Äá[00:18&lt;00:00,‚Äá333.80‚Äáexamples/s]"
          }
        },
        "a96d6f7b57684f4694640e30cab7d57f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d76972ffafa14af38705d9a0dc4c41e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bd700ee97cc45f886b87e0c241f30d5",
              "IPY_MODEL_0ff56ffaf21b4b6fa454c851b63c39f3",
              "IPY_MODEL_a72c0ed5c766416d8ca2261545b8d7ab"
            ],
            "layout": "IPY_MODEL_9c99e147fd4b4c92bd9f15ce8379f71e"
          }
        },
        "d87ee7784e7c4cccab29e8aef0d9bc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc605f74c14b4bfd99ce5db31f5bada0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deb17ec2d2cf442a9a08d92fd0b56af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f04663ee3e3f4a7c9934f078357fd55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f972a2389d4240dd877d04871f9f11f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a96d6f7b57684f4694640e30cab7d57f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dc605f74c14b4bfd99ce5db31f5bada0",
            "value": "‚Äá25612/25612‚Äá[01:11&lt;00:00,‚Äá303.93‚Äáexamples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
